{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh0RR5d8WxrM"
      },
      "source": [
        "# Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLOvylZHWwnP"
      },
      "outputs": [],
      "source": [
        "# Copyright 2017 Google Inc.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Returns points that minimizes the maximum distance of any point to a center.\n",
        "Implements the k-Center-Greedy method in\n",
        "Ozan Sener and Silvio Savarese.  A Geometric Approach to Active Learning for\n",
        "Convolutional Neural Networks. https://arxiv.org/abs/1708.00489 2017\n",
        "Distance metric defaults to l2 distance.  Features used to calculate distance\n",
        "are either raw features or if a model has transform method then uses the output\n",
        "of model.transform(X).\n",
        "Can be extended to a robust k centers algorithm that ignores a certain number of\n",
        "outlier datapoints.  Resulting centers are solution to multiple integer program.\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import abc\n",
        "import numpy as np\n",
        "\n",
        "class SamplingMethod(object):\n",
        "  __metaclass__ = abc.ABCMeta\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def __init__(self, X, y, seed, **kwargs):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.seed = seed\n",
        "\n",
        "  def flatten_X(self):\n",
        "    shape = self.X.shape\n",
        "    flat_X = self.X\n",
        "    if len(shape) > 2:\n",
        "      flat_X = np.reshape(self.X, (shape[0],np.product(shape[1:])))\n",
        "    return flat_X\n",
        "\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def select_batch_(self):\n",
        "    return\n",
        "\n",
        "  def select_batch(self, **kwargs):\n",
        "    return self.select_batch_(**kwargs)\n",
        "\n",
        "  def to_dict(self):\n",
        "    return None\n",
        "\n",
        "class kCenterGreedy(SamplingMethod):\n",
        "\n",
        "  def __init__(self, X, y, seed, metric='euclidean'):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.flat_X = self.flatten_X()\n",
        "    self.name = 'kcenter'\n",
        "    self.features = self.flat_X\n",
        "    self.metric = metric\n",
        "    self.min_distances = None\n",
        "    self.n_obs = self.X.shape[0]\n",
        "    self.already_selected = []\n",
        "\n",
        "  def update_distances(self, cluster_centers, only_new=True, reset_dist=False):\n",
        "    \"\"\"Update min distances given cluster centers.\n",
        "    Args:\n",
        "      cluster_centers: indices of cluster centers\n",
        "      only_new: only calculate distance for newly selected points and update\n",
        "        min_distances.\n",
        "      rest_dist: whether to reset min_distances.\n",
        "    \"\"\"\n",
        "\n",
        "    if reset_dist:\n",
        "      self.min_distances = None\n",
        "    if only_new:\n",
        "      cluster_centers = [d for d in cluster_centers\n",
        "                         if d not in self.already_selected]\n",
        "    if cluster_centers:\n",
        "      # Update min_distances for all examples given new cluster center.\n",
        "      x = self.features[cluster_centers]\n",
        "      dist = pairwise_distances(self.features, x, metric=self.metric)\n",
        "\n",
        "      if self.min_distances is None:\n",
        "        self.min_distances = np.min(dist, axis=1).reshape(-1,1)\n",
        "      else:\n",
        "        self.min_distances = np.minimum(self.min_distances, dist)\n",
        "\n",
        "  def select_batch_(self, model, already_selected, N, **kwargs):\n",
        "    \"\"\"\n",
        "    Diversity promoting active learning method that greedily forms a batch\n",
        "    to minimize the maximum distance to a cluster center among all unlabeled\n",
        "    datapoints.\n",
        "    Args:\n",
        "      model: model with scikit-like API with decision_function implemented\n",
        "      already_selected: index of datapoints already selected\n",
        "      N: batch size\n",
        "    Returns:\n",
        "      indices of points selected to minimize distance to cluster centers\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "      # Assumes that the transform function takes in original data and not\n",
        "      # flattened data.\n",
        "      print('Getting transformed features...')\n",
        "      if model:\n",
        "        self.features = model.transform(self.X)\n",
        "      else:\n",
        "        self.features = self.X\n",
        "      \n",
        "      print('Calculating distances...')\n",
        "      self.update_distances(already_selected, only_new=False, reset_dist=True)\n",
        "    except:\n",
        "      print('Using flat_X as features.')\n",
        "      self.update_distances(already_selected, only_new=True, reset_dist=False)\n",
        "\n",
        "    new_batch = []\n",
        "\n",
        "    for _ in tqdm(range(N)):\n",
        "      if self.already_selected is None:\n",
        "        # Initialize centers with a randomly selected datapoint\n",
        "        ind = np.random.choice(np.arange(self.n_obs))\n",
        "      else:\n",
        "        ind = np.argmax(self.min_distances)\n",
        "      # New examples should not be in already selected since those points\n",
        "      # should have min_distance of zero to a cluster center.\n",
        "      assert ind not in already_selected\n",
        "\n",
        "      self.update_distances([ind], only_new=True, reset_dist=False)\n",
        "      new_batch.append(ind)\n",
        "\n",
        "    self.already_selected = already_selected\n",
        "    return new_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJQmJcxrjHZJ"
      },
      "source": [
        "# Coreset sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmP5mnMuJEcZ",
        "outputId": "2cfdfbd0-4a06-433a-b5ee-5dc4ee8045d3"
      },
      "outputs": [],
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1_DqWsmjH6v",
        "outputId": "c6a68bf3-45d2-45a0-8e42-c7b22e4f1a40"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.random_projection import SparseRandomProjection\n",
        "\n",
        "\n",
        "_to_test = ['bottle', 'cable',\n",
        "            'capsule', 'carpet',\n",
        "            'grid', 'hazelnut', \n",
        "            'leather', 'metalnut', \n",
        "            'pill', 'screw', \n",
        "            'tile', 'toothbrush', \n",
        "            'transistor', 'wood', \n",
        "            'zipper'\n",
        "            ]\n",
        "\n",
        "embeddings_path = 'drive/MyDrive/data/efficientnet_embeddings_b7'\n",
        "\n",
        "def reshape_embedding(embedding):\n",
        "    embedding_list = []\n",
        "    for k in range(embedding.shape[0]):\n",
        "        for i in range(embedding.shape[2]):\n",
        "            for j in range(embedding.shape[3]):\n",
        "                embedding_list.append(embedding[k, :, i, j])\n",
        "    return embedding_list\n",
        "\n",
        "def embedding_concat(x, y):\n",
        "    # from https://github.com/xiahaifeng1995/PaDiM-Anomaly-Detection-Localization-master\n",
        "    B, C1, H1, W1 = x.size()\n",
        "    _, C2, H2, W2 = y.size()\n",
        "    s = int(H1 / H2)\n",
        "    x = F.unfold(x, kernel_size=s, dilation=1, stride=s)\n",
        "    x = x.view(B, C1, -1, H2, W2)\n",
        "    z = torch.zeros(B, C1 + C2, x.size(2), H2, W2)\n",
        "    for i in range(x.size(2)):\n",
        "        z[:, :, i, :, :] = torch.cat((x[:, :, i, :, :], y), 1)\n",
        "    z = z.view(B, -1, H2 * W2)\n",
        "    z = F.fold(z, kernel_size=s, output_size=(H1, W1), stride=s)\n",
        "\n",
        "    return z\n",
        "\n",
        "for category in _to_test:\n",
        "\n",
        "  print(category)\n",
        "\n",
        "  layer_combis = [[\"3\", \"4\"],\n",
        "                  [\"4\", \"5\"],\n",
        "                  [\"3\", \"5\"],\n",
        "                  [\"3\", \"4\", \"5\"]]\n",
        "  for layer_combi in layer_combis:\n",
        "\n",
        "    print('\\tLayer:', '_'.join(layer_combi), end=' ')\n",
        "    f_name = f'{embeddings_path}/{category}/layer_{\"_\".join(layer_combi)}/embedding_train_projected_greedy.pickle'\n",
        "    \n",
        "    if os.path.isfile(f_name):\n",
        "      print('done!')\n",
        "      continue\n",
        "\n",
        "    embeddings_reshaped = []\n",
        "    embeddings_single = {}\n",
        "    for layer in layer_combi:\n",
        "      with open(f'{embeddings_path}/{category}/layer_{layer}/embedding_train_projected.pickle', 'rb') as f:\n",
        "        embeddings_single[layer] = pickle.load(f)['embedding']\n",
        "\n",
        "    for ix, _ in enumerate(embeddings_single[layer_combi[0]]):\n",
        "      embedding = embedding_concat(torch.FloatTensor(embeddings_single[layer_combi[0]][ix]),\n",
        "                                   torch.FloatTensor(embeddings_single[layer_combi[1]][ix])\n",
        "                                   )\n",
        "      \n",
        "      if len(layer_combi) == 3:\n",
        "        embedding = embedding_concat(embedding, torch.FloatTensor(embeddings_single[layer_combi[2]][ix]))\n",
        "      print(embedding.size())\n",
        "      embeddings_reshaped.extend(reshape_embedding(embedding.cpu().detach().numpy()))\n",
        "\n",
        "    embeddings_train = np.array(embeddings_reshaped)\n",
        "    print(embeddings_train.shape, end=' - ')\n",
        "    # Random projection\n",
        "    try:\n",
        "      randomprojector = SparseRandomProjection(n_components='auto', eps=0.9) # 'auto' => Johnson-Lindenstrauss lemma\n",
        "      randomprojector.fit(embeddings_train)\n",
        "    except:\n",
        "      randomprojector = SparseRandomProjection(n_components=embeddings_train.shape[1]) # 'auto' => Johnson-Lindenstrauss lemma\n",
        "      randomprojector.fit(embeddings_train)\n",
        "\n",
        "    # Coreset Subsampling\n",
        "    selector = kCenterGreedy(embeddings_train,0,0)\n",
        "    selected_idx = selector.select_batch(model=randomprojector, already_selected=[], N=min(int(embeddings_train.shape[0]*0.5), 15000))\n",
        "    embedding_coreset = embeddings_train[selected_idx]\n",
        "    if not os.path.isdir(f'{embeddings_path}/{category}/layer_{\"_\".join(layer_combi)}'):\n",
        "      os.mkdir(f'{embeddings_path}/{category}/layer_{\"_\".join(layer_combi)}')\n",
        "    with open(f_name, 'wb') as f:\n",
        "      pickle.dump({'embedding': embedding_coreset}, f) \n",
        "    print('done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FclvXyKgNmyy"
      },
      "source": [
        "# Single Patch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjQjMCBPnH5m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.random_projection import SparseRandomProjection\n",
        "\n",
        "\n",
        "_to_test = ['bottle', 'cable', 'capsule', 'carpet', 'grid',\n",
        "            'hazelnut', 'leather', 'metalnut', 'pill', 'screw', \n",
        "            'tile', 'toothbrush', 'transistor', 'wood', 'zipper']\n",
        "\n",
        "embeddings_path = 'drive/MyDrive/data/efficientnet_embeddings_b3'\n",
        "\n",
        "def reshape_embedding(embedding):\n",
        "    embedding_list = []\n",
        "    for k in range(embedding.shape[0]):\n",
        "        for i in range(embedding.shape[2]):\n",
        "            for j in range(embedding.shape[3]):\n",
        "                embedding_list.append(embedding[k, :, i, j])\n",
        "    return embedding_list\n",
        "\n",
        "for category in _to_test:\n",
        "\n",
        "  print(category)\n",
        "\n",
        "  for layer in range(1,8):\n",
        "\n",
        "    print('\\tLayer:', layer, end=' ')\n",
        "    f_name = f'{embeddings_path}/{category}/layer_{layer}/embedding_train_projected_greedy.pickle'\n",
        "    \n",
        "    if os.path.isfile(f_name):\n",
        "      print('done!')\n",
        "      continue\n",
        "\n",
        "    with open(f'{embeddings_path}/{category}/layer_{layer}/embedding_train_projected.pickle', 'rb') as f:\n",
        "      embeddings_train_full = pickle.load(f)['embedding']\n",
        "\n",
        "    embeddings_reshaped = []\n",
        "    for i in embeddings_train_full:\n",
        "      embeddings_reshaped.extend(reshape_embedding(np.array(i)))\n",
        "\n",
        "    embeddings_train = np.array(embeddings_reshaped)\n",
        "    print(embeddings_train.shape, end=' - ')\n",
        "    # Random projection\n",
        "    try:\n",
        "      randomprojector = SparseRandomProjection(n_components='auto', eps=0.9) # 'auto' => Johnson-Lindenstrauss lemma\n",
        "      randomprojector.fit(embeddings_train)\n",
        "    except:\n",
        "      randomprojector = SparseRandomProjection(n_components=embeddings_train.shape[1]) # 'auto' => Johnson-Lindenstrauss lemma\n",
        "      randomprojector.fit(embeddings_train)\n",
        "\n",
        "    # Coreset Subsampling\n",
        "    selector = kCenterGreedy(embeddings_train,0,0)\n",
        "    selected_idx = selector.select_batch(model=randomprojector, already_selected=[], N=min(int(embeddings_train.shape[0]*0.5), 15000))\n",
        "    embedding_coreset = embeddings_train[selected_idx]\n",
        "    with open(f_name, 'wb') as f:\n",
        "      pickle.dump({'embedding': embedding_coreset}, f) \n",
        "    print('done!')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "coresampling.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
